{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "\n",
    "# Configure GPU memory growth to avoid memory allocation errors\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# 1. Feature Extraction\n",
    "class HandFeatureExtractor:\n",
    "    def __init__(self, static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5):\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=static_image_mode,\n",
    "            max_num_hands=max_num_hands,\n",
    "            min_detection_confidence=min_detection_confidence,\n",
    "            min_tracking_confidence=min_tracking_confidence\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "    def extract_landmarks(self, frame):\n",
    "        # Convert frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process frame with MediaPipe\n",
    "        results = self.hands.process(frame_rgb)\n",
    "        \n",
    "        landmarks_list = []\n",
    "        handedness_list = []\n",
    "        \n",
    "        # Check if hands were detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                # Get hand type (left/right)\n",
    "                handedness = results.multi_handedness[idx].classification[0].label\n",
    "                \n",
    "                # Extract landmarks\n",
    "                landmarks = []\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
    "                \n",
    "                landmarks_list.append(landmarks)\n",
    "                handedness_list.append(handedness)\n",
    "                \n",
    "                # Draw landmarks on frame for visualization\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "        return frame, landmarks_list, handedness_list\n",
    "    \n",
    "    def close(self):\n",
    "        self.hands.close()\n",
    "\n",
    "# 2. Dataset Class\n",
    "class SignLanguageDataset:\n",
    "    def __init__(self, sequence_length=30, overlap=0.5):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.overlap = overlap\n",
    "        self.extractor = HandFeatureExtractor()\n",
    "        self.classes = []\n",
    "        self.X_train = []\n",
    "        self.y_train = []\n",
    "        self.X_val = []\n",
    "        self.y_val = []\n",
    "        \n",
    "    def process_video(self, video_path, label):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Extract hand landmarks\n",
    "            _, landmarks_list, _ = self.extractor.extract_landmarks(frame)\n",
    "            \n",
    "            # Use the first detected hand's landmarks or zero padding if no hand detected\n",
    "            if landmarks_list:\n",
    "                frames.append(landmarks_list[0])  # Use first hand's landmarks\n",
    "            else:\n",
    "                frames.append([0.0] * 63)  # Zero padding for 21 landmarks (x,y,z)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Create sequences with overlap\n",
    "        sequences = []\n",
    "        step = int(self.sequence_length * (1 - self.overlap))\n",
    "        \n",
    "        for i in range(0, len(frames) - self.sequence_length + 1, step):\n",
    "            sequences.append(frames[i:i + self.sequence_length])\n",
    "        \n",
    "        return sequences, [label] * len(sequences)\n",
    "    \n",
    "    def load_dataset(self, dataset_dir, train_split=0.8):\n",
    "        self.classes = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])\n",
    "        class_to_index = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        \n",
    "        all_sequences = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Process each video for each class\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(dataset_dir, class_name)\n",
    "            video_files = [f for f in os.listdir(class_dir) if f.endswith(('.mp4', '.avi'))]\n",
    "            \n",
    "            for video_file in video_files:\n",
    "                video_path = os.path.join(class_dir, video_file)\n",
    "                sequences, labels = self.process_video(video_path, class_to_index[class_name])\n",
    "                all_sequences.extend(sequences)\n",
    "                all_labels.extend(labels)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        all_sequences = np.array(all_sequences)\n",
    "        all_labels = np.array(all_labels)\n",
    "        \n",
    "        # Shuffle the dataset\n",
    "        indices = np.random.permutation(len(all_sequences))\n",
    "        all_sequences = all_sequences[indices]\n",
    "        all_labels = all_labels[indices]\n",
    "        \n",
    "        # Split into train and validation\n",
    "        split_idx = int(len(all_sequences) * train_split)\n",
    "        self.X_train = all_sequences[:split_idx]\n",
    "        self.y_train = all_labels[:split_idx]\n",
    "        self.X_val = all_sequences[split_idx:]\n",
    "        self.y_val = all_labels[split_idx:]\n",
    "        \n",
    "        print(f\"Loaded {len(self.X_train)} training sequences and {len(self.X_val)} validation sequences\")\n",
    "        print(f\"Classes: {self.classes}\")\n",
    "        \n",
    "        return self.X_train, self.y_train, self.X_val, self.y_val, self.classes\n",
    "    \n",
    "    def save_processed_dataset(self, output_path):\n",
    "        \"\"\"Save processed dataset to disk\"\"\"\n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'X_train': self.X_train,\n",
    "                'y_train': self.y_train,\n",
    "                'X_val': self.X_val,\n",
    "                'y_val': self.y_val,\n",
    "                'classes': self.classes\n",
    "            }, f)\n",
    "        \n",
    "    def load_processed_dataset(self, input_path):\n",
    "        \"\"\"Load processed dataset from disk\"\"\"\n",
    "        with open(input_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.X_train = data['X_train']\n",
    "            self.y_train = data['y_train']\n",
    "            self.X_val = data['X_val']\n",
    "            self.y_val = data['y_val']\n",
    "            self.classes = data['classes']\n",
    "        \n",
    "        return self.X_train, self.y_train, self.X_val, self.y_val, self.classes\n",
    "\n",
    "# 3. Data Augmentation\n",
    "class HandLandmarkAugmenter:\n",
    "    \"\"\"Data augmentation for hand landmarks\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_noise(landmarks, noise_level=0.01):\n",
    "        \"\"\"Add random noise to landmarks\"\"\"\n",
    "        noise = np.random.normal(0, noise_level, landmarks.shape)\n",
    "        return landmarks + noise\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale(landmarks, scale_range=(0.9, 1.1)):\n",
    "        \"\"\"Scale landmarks\"\"\"\n",
    "        scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "        # Only scale x,y coordinates (every 3rd element)\n",
    "        scaled = landmarks.copy()\n",
    "        scaled[:, :, 0::3] *= scale  # x coordinates\n",
    "        scaled[:, :, 1::3] *= scale  # y coordinates\n",
    "        return scaled\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate(landmarks, angle_range=(-15, 15)):\n",
    "        \"\"\"Rotate landmarks in 2D space\"\"\"\n",
    "        angle = np.random.uniform(angle_range[0], angle_range[1])\n",
    "        angle_rad = np.radians(angle)\n",
    "        \n",
    "        rotated = landmarks.copy()\n",
    "        \n",
    "        # Extract x and y coordinates\n",
    "        x = landmarks[:, :, 0::3]  # x coordinates\n",
    "        y = landmarks[:, :, 1::3]  # y coordinates\n",
    "        \n",
    "        # Apply rotation\n",
    "        rotated_x = x * np.cos(angle_rad) - y * np.sin(angle_rad)\n",
    "        rotated_y = x * np.sin(angle_rad) + y * np.cos(angle_rad)\n",
    "        \n",
    "        # Put back to original structure\n",
    "        rotated[:, :, 0::3] = rotated_x\n",
    "        rotated[:, :, 1::3] = rotated_y\n",
    "        \n",
    "        return rotated\n",
    "    \n",
    "    @staticmethod\n",
    "    def time_warp(landmarks, warp_factor=0.2):\n",
    "        \"\"\"Warp time dimension slightly (stretch/compress)\"\"\"\n",
    "        seq_len = landmarks.shape[1]\n",
    "        warp = np.random.uniform(1-warp_factor, 1+warp_factor)\n",
    "        \n",
    "        # Create new time indices\n",
    "        old_indices = np.arange(seq_len)\n",
    "        new_indices = np.linspace(0, seq_len-1, seq_len) * warp\n",
    "        new_indices = np.clip(new_indices, 0, seq_len-1)\n",
    "        \n",
    "        # Interpolate\n",
    "        warped = np.zeros_like(landmarks)\n",
    "        for i in range(landmarks.shape[0]):\n",
    "            for j in range(landmarks.shape[2]):\n",
    "                warped[i, :, j] = np.interp(new_indices, old_indices, landmarks[i, :, j])\n",
    "        \n",
    "        return warped\n",
    "    \n",
    "    @staticmethod\n",
    "    def augment_batch(X_batch, augmentation_probability=0.5):\n",
    "        \"\"\"Apply random augmentations to a batch\"\"\"\n",
    "        X_aug = X_batch.copy()\n",
    "        \n",
    "        for i in range(len(X_aug)):\n",
    "            if np.random.random() < augmentation_probability:\n",
    "                # Choose random augmentations\n",
    "                if np.random.random() < 0.5:\n",
    "                    X_aug[i] = HandLandmarkAugmenter.add_noise(X_aug[i:i+1])[0]\n",
    "                if np.random.random() < 0.5:\n",
    "                    X_aug[i] = HandLandmarkAugmenter.scale(X_aug[i:i+1])[0]\n",
    "                if np.random.random() < 0.5:\n",
    "                    X_aug[i] = HandLandmarkAugmenter.rotate(X_aug[i:i+1])[0]\n",
    "                if np.random.random() < 0.5:\n",
    "                    X_aug[i] = HandLandmarkAugmenter.time_warp(X_aug[i:i+1])[0]\n",
    "        \n",
    "        return X_aug\n",
    "\n",
    "# 4. Custom Data Generator\n",
    "class SignLanguageDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Data generator for training with on-the-fly augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True, augment=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.augmenter = HandLandmarkAugmenter()\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of batches per epoch\"\"\"\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "        # Generate indices of the batch\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        # Generate data\n",
    "        X_batch = self.X[batch_indices]\n",
    "        y_batch = self.y[batch_indices]\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.augment:\n",
    "            X_batch = self.augmenter.augment_batch(X_batch)\n",
    "        \n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indices after each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# 5. Advanced Model Architecture\n",
    "def build_advanced_sign_language_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build an advanced sign language recognition model with:\n",
    "    - Temporal convolutional layers\n",
    "    - Bidirectional LSTM layers\n",
    "    - Attention mechanism\n",
    "    - Residual connections\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Normalization layer\n",
    "    norm_layer = tf.keras.layers.LayerNormalization()(inputs)\n",
    "    \n",
    "    # 1D Convolutional layers for temporal feature extraction\n",
    "    conv1 = tf.keras.layers.Conv1D(64, kernel_size=3, padding='same', activation='relu')(norm_layer)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.SpatialDropout1D(0.1)(conv1)\n",
    "    \n",
    "    conv2 = tf.keras.layers.Conv1D(128, kernel_size=3, padding='same', activation='relu')(conv1)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = tf.keras.layers.SpatialDropout1D(0.1)(conv2)\n",
    "    \n",
    "    # Residual connection\n",
    "    res_conn = tf.keras.layers.Add()([conv1, tf.keras.layers.Conv1D(128, kernel_size=1, padding='same')(conv1)])\n",
    "    combined = tf.keras.layers.Add()([conv2, res_conn])\n",
    "    \n",
    "    # Bidirectional LSTM layers for sequence modeling\n",
    "    lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(combined)\n",
    "    lstm1 = tf.keras.layers.BatchNormalization()(lstm1)\n",
    "    \n",
    "    lstm2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(lstm1)\n",
    "    lstm2 = tf.keras.layers.BatchNormalization()(lstm2)\n",
    "    \n",
    "    # Self-attention mechanism\n",
    "    attention = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=32)(lstm2, lstm2)\n",
    "    attention = tf.keras.layers.LayerNormalization()(attention + lstm2)  # Skip connection\n",
    "    \n",
    "    # Global temporal pooling\n",
    "    gap = tf.keras.layers.GlobalAveragePooling1D()(attention)\n",
    "    \n",
    "    # Final dense layers\n",
    "    dense1 = tf.keras.layers.Dense(256, activation='relu')(gap)\n",
    "    dense1 = tf.keras.layers.BatchNormalization()(dense1)\n",
    "    dense1 = tf.keras.layers.Dropout(0.3)(dense1)\n",
    "    \n",
    "    dense2 = tf.keras.layers.Dense(128, activation='relu')(dense1)\n",
    "    dense2 = tf.keras.layers.BatchNormalization()(dense2)\n",
    "    dense2 = tf.keras.layers.Dropout(0.2)(dense2)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(dense2)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, num_classes, sequence_length, num_features):\n",
    "    \"\"\"Train the model with advanced techniques\"\"\"\n",
    "    \n",
    "    # Define input shape\n",
    "    input_shape = (sequence_length, num_features)\n",
    "    \n",
    "    # Build model\n",
    "    model = build_advanced_sign_language_model(input_shape, num_classes)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        # Learning rate scheduler\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # Early stopping\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # Model checkpoint\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_sign_language_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # TensorBoard logging\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "class HandLandmarkAugmenter:\n",
    "    \"\"\"Data augmentation for hand landmarks\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_noise(landmarks, noise_level=0.01):\n",
    "        \"\"\"Add random noise to landmarks\"\"\"\n",
    "        noise = np.random.normal(0, noise_level, landmarks.shape)\n",
    "        return landmarks + noise\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale(landmarks, scale_range=(0.9, 1.1)):\n",
    "        \"\"\"Scale landmarks\"\"\"\n",
    "        scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "        # Only scale x,y coordinates (every 3rd element)\n",
    "        scaled = landmarks.copy()\n",
    "        scaled[:, :, 0::3] *= scale  # x coordinates\n",
    "        scaled[:, :, 1::3] *= scale  # y coordinates\n",
    "        return scaled\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate(landmarks, angle_range=(-15, 15)):\n",
    "        \"\"\"Rotate landmarks in 2D space\"\"\"\n",
    "        angle = np.random.uniform(angle_range[0], angle_range[1])\n",
    "        angle_rad = np.radians(angle)\n",
    "        \n",
    "        rotated = landmarks.copy()\n",
    "        \n",
    "        # Extract x and y coordinates\n",
    "        x = landmarks[:, :, 0::3]  # x coordinates\n",
    "        y = landmarks[:, :, 1::3]  # y coordinates\n",
    "        \n",
    "        # Apply rotation\n",
    "        rotated_x = x * np.cos(angle_rad) - y * np.sin(angle_rad)\n",
    "        rotated_y = x * np.sin(angle_rad) + y * np.cos(angle_rad)\n",
    "        \n",
    "        # Put back to original structure\n",
    "        rotated[:, :, 0::3] = rotated_x\n",
    "        rotated[:, :, 1::3] = rotated_y\n",
    "        \n",
    "        return rotated\n",
    "    \n",
    "    @staticmethod\n",
    "    def time_warp(landmarks, warp_factor=0.2):\n",
    "        \"\"\"Warp time dimension slightly (stretch/compress)\"\"\"\n",
    "        seq_len = landmarks.shape[1]\n",
    "        warp = np.random.uniform(1-warp_factor, 1+warp_factor)\n",
    "        \n",
    "        # Create new time indices\n",
    "        old_indices = np.arange(seq_len)\n",
    "        new_indices = np.linspace(0, seq_len-1, seq_len) * warp\n",
    "        new_indices = np.clip(new_indices, 0, seq_len-1)\n",
    "        \n",
    "        # Interpolate\n",
    "        warped = np.zeros_like(landmarks)\n",
    "        for i in range(landmarks.shape[0]):\n",
    "            for j in range(landmarks.shape[2]):\n",
    "                warped[i, :, j] = np.interp(new_indices, old_indices, landmarks[i, :, j])\n",
    "        \n",
    "        return warped\n",
    "    \n",
    "    @staticmethod\n",
    "    def augment_batch(X_batch, augmentation_probability=0.5):\n",
    "        \"\"\"Apply random augmentations to a batch\"\"\"\n",
    "        X_aug = X_batch.copy()\n",
    "        \n",
    "        for i in range(len(X_aug)):\n",
    "            if np.random.random() < augmentation_probability:\n",
    "                # Choose random augmentations\n",
    "                if np.random.random() < 0.5:\n",
    "                    X_aug[i] = HandLandmarkAugmenter.add_noise(X_aug[i:i+1])[0]\n",
    "                if np.random.random() < 0.5:\n",
    "                    X_aug[i] = HandLandmarkAugmenter.scale(X_aug[i:i+1])[0]\n",
    "                if np.random.random() < 0.5:\n",
    "                    X_aug[i] = HandLandmarkAugmenter.rotate(X_aug[i:i+1])[0]\n",
    "                if np.random.random() < 0.5:\n",
    "                    X_aug[i] = HandLandmarkAugmenter.time_warp(X_aug[i:i+1])[0]\n",
    "        \n",
    "        return X_aug\n",
    "    \n",
    "    class SignLanguageDataGenerator(tf.keras.utils.Sequence):\n",
    "        \"\"\"Data generator for training with on-the-fly augmentation\"\"\"\n",
    "        \n",
    "        def __init__(self, X, y, batch_size=32, shuffle=True, augment=True):\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.batch_size = batch_size\n",
    "            self.shuffle = shuffle\n",
    "            self.augment = augment\n",
    "            self.indices = np.arange(len(self.X))\n",
    "            self.augmenter = HandLandmarkAugmenter()\n",
    "            self.on_epoch_end()\n",
    "        \n",
    "        def __len__(self):\n",
    "            \"\"\"Return the number of batches per epoch\"\"\"\n",
    "            return int(np.ceil(len(self.X) / self.batch_size))\n",
    "        \n",
    "        def __getitem__(self, index):\n",
    "            \"\"\"Generate one batch of data\"\"\"\n",
    "            # Generate indices of the batch\n",
    "            batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "            \n",
    "            # Generate data\n",
    "            X_batch = self.X[batch_indices]\n",
    "            y_batch = self.y[batch_indices]\n",
    "            \n",
    "            # Apply augmentation\n",
    "            if self.augment:\n",
    "                X_batch = self.augmenter.augment_batch(X_batch)\n",
    "            \n",
    "            return X_batch, y_batch\n",
    "        \n",
    "        def on_epoch_end(self):\n",
    "            \"\"\"Updates indices after each epoch\"\"\"\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand_ges_det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
